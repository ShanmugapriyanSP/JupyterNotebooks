{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15624510</td>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>19000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15810944</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15668575</td>\n",
       "      <td>Female</td>\n",
       "      <td>26</td>\n",
       "      <td>43000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15603246</td>\n",
       "      <td>Female</td>\n",
       "      <td>27</td>\n",
       "      <td>57000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15804002</td>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>76000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    User ID  Gender  Age  EstimatedSalary  Purchased\n",
       "0  15624510    Male   19            19000          0\n",
       "1  15810944    Male   35            20000          0\n",
       "2  15668575  Female   26            43000          0\n",
       "3  15603246  Female   27            57000          0\n",
       "4  15804002    Male   19            76000          0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('.\\\\files\\\\Social_Network_Ads.csv')\n",
    "x = dataset.iloc[:, 2:4].values\n",
    "y = dataset.iloc[:, 4].values\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc_x = StandardScaler()\n",
    "x_train = sc_x.fit_transform(x_train)\n",
    "x_test = sc_x.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class SVC in module sklearn.svm.classes:\n",
      "\n",
      "class SVC(sklearn.svm.base.BaseSVC)\n",
      " |  SVC(C=1.0, kernel='rbf', degree=3, gamma='auto_deprecated', coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, decision_function_shape='ovr', random_state=None)\n",
      " |  \n",
      " |  C-Support Vector Classification.\n",
      " |  \n",
      " |  The implementation is based on libsvm. The fit time scales at least\n",
      " |  quadratically with the number of samples and may be impractical\n",
      " |  beyond tens of thousands of samples. For large datasets\n",
      " |  consider using :class:`sklearn.linear_model.LinearSVC` or\n",
      " |  :class:`sklearn.linear_model.SGDClassifier` instead, possibly after a\n",
      " |  :class:`sklearn.kernel_approximation.Nystroem` transformer.\n",
      " |  \n",
      " |  The multiclass support is handled according to a one-vs-one scheme.\n",
      " |  \n",
      " |  For details on the precise mathematical formulation of the provided\n",
      " |  kernel functions and how `gamma`, `coef0` and `degree` affect each\n",
      " |  other, see the corresponding section in the narrative documentation:\n",
      " |  :ref:`svm_kernels`.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <svm_classification>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  C : float, optional (default=1.0)\n",
      " |      Penalty parameter C of the error term.\n",
      " |  \n",
      " |  kernel : string, optional (default='rbf')\n",
      " |      Specifies the kernel type to be used in the algorithm.\n",
      " |      It must be one of 'linear', 'poly', 'rbf', 'sigmoid', 'precomputed' or\n",
      " |      a callable.\n",
      " |      If none is given, 'rbf' will be used. If a callable is given it is\n",
      " |      used to pre-compute the kernel matrix from data matrices; that matrix\n",
      " |      should be an array of shape ``(n_samples, n_samples)``.\n",
      " |  \n",
      " |  degree : int, optional (default=3)\n",
      " |      Degree of the polynomial kernel function ('poly').\n",
      " |      Ignored by all other kernels.\n",
      " |  \n",
      " |  gamma : float, optional (default='auto')\n",
      " |      Kernel coefficient for 'rbf', 'poly' and 'sigmoid'.\n",
      " |  \n",
      " |      Current default is 'auto' which uses 1 / n_features,\n",
      " |      if ``gamma='scale'`` is passed then it uses 1 / (n_features * X.var())\n",
      " |      as value of gamma. The current default of gamma, 'auto', will change\n",
      " |      to 'scale' in version 0.22. 'auto_deprecated', a deprecated version of\n",
      " |      'auto' is used as a default indicating that no explicit value of gamma\n",
      " |      was passed.\n",
      " |  \n",
      " |  coef0 : float, optional (default=0.0)\n",
      " |      Independent term in kernel function.\n",
      " |      It is only significant in 'poly' and 'sigmoid'.\n",
      " |  \n",
      " |  shrinking : boolean, optional (default=True)\n",
      " |      Whether to use the shrinking heuristic.\n",
      " |  \n",
      " |  probability : boolean, optional (default=False)\n",
      " |      Whether to enable probability estimates. This must be enabled prior\n",
      " |      to calling `fit`, and will slow down that method.\n",
      " |  \n",
      " |  tol : float, optional (default=1e-3)\n",
      " |      Tolerance for stopping criterion.\n",
      " |  \n",
      " |  cache_size : float, optional\n",
      " |      Specify the size of the kernel cache (in MB).\n",
      " |  \n",
      " |  class_weight : {dict, 'balanced'}, optional\n",
      " |      Set the parameter C of class i to class_weight[i]*C for\n",
      " |      SVC. If not given, all classes are supposed to have\n",
      " |      weight one.\n",
      " |      The \"balanced\" mode uses the values of y to automatically adjust\n",
      " |      weights inversely proportional to class frequencies in the input data\n",
      " |      as ``n_samples / (n_classes * np.bincount(y))``\n",
      " |  \n",
      " |  verbose : bool, default: False\n",
      " |      Enable verbose output. Note that this setting takes advantage of a\n",
      " |      per-process runtime setting in libsvm that, if enabled, may not work\n",
      " |      properly in a multithreaded context.\n",
      " |  \n",
      " |  max_iter : int, optional (default=-1)\n",
      " |      Hard limit on iterations within solver, or -1 for no limit.\n",
      " |  \n",
      " |  decision_function_shape : 'ovo', 'ovr', default='ovr'\n",
      " |      Whether to return a one-vs-rest ('ovr') decision function of shape\n",
      " |      (n_samples, n_classes) as all other classifiers, or the original\n",
      " |      one-vs-one ('ovo') decision function of libsvm which has shape\n",
      " |      (n_samples, n_classes * (n_classes - 1) / 2). However, one-vs-one\n",
      " |      ('ovo') is always used as multi-class strategy.\n",
      " |  \n",
      " |      .. versionchanged:: 0.19\n",
      " |          decision_function_shape is 'ovr' by default.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         *decision_function_shape='ovr'* is recommended.\n",
      " |  \n",
      " |      .. versionchanged:: 0.17\n",
      " |         Deprecated *decision_function_shape='ovo' and None*.\n",
      " |  \n",
      " |  random_state : int, RandomState instance or None, optional (default=None)\n",
      " |      The seed of the pseudo random number generator used when shuffling\n",
      " |      the data for probability estimates. If int, random_state is the\n",
      " |      seed used by the random number generator; If RandomState instance,\n",
      " |      random_state is the random number generator; If None, the random\n",
      " |      number generator is the RandomState instance used by `np.random`.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  support_ : array-like, shape = [n_SV]\n",
      " |      Indices of support vectors.\n",
      " |  \n",
      " |  support_vectors_ : array-like, shape = [n_SV, n_features]\n",
      " |      Support vectors.\n",
      " |  \n",
      " |  n_support_ : array-like, dtype=int32, shape = [n_class]\n",
      " |      Number of support vectors for each class.\n",
      " |  \n",
      " |  dual_coef_ : array, shape = [n_class-1, n_SV]\n",
      " |      Coefficients of the support vector in the decision function.\n",
      " |      For multiclass, coefficient for all 1-vs-1 classifiers.\n",
      " |      The layout of the coefficients in the multiclass case is somewhat\n",
      " |      non-trivial. See the section about multi-class classification in the\n",
      " |      SVM section of the User Guide for details.\n",
      " |  \n",
      " |  coef_ : array, shape = [n_class * (n_class-1) / 2, n_features]\n",
      " |      Weights assigned to the features (coefficients in the primal\n",
      " |      problem). This is only available in the case of a linear kernel.\n",
      " |  \n",
      " |      `coef_` is a readonly property derived from `dual_coef_` and\n",
      " |      `support_vectors_`.\n",
      " |  \n",
      " |  intercept_ : array, shape = [n_class * (n_class-1) / 2]\n",
      " |      Constants in decision function.\n",
      " |  \n",
      " |  fit_status_ : int\n",
      " |      0 if correctly fitted, 1 otherwise (will raise warning)\n",
      " |  \n",
      " |  probA_ : array, shape = [n_class * (n_class-1) / 2]\n",
      " |  probB_ : array, shape = [n_class * (n_class-1) / 2]\n",
      " |      If probability=True, the parameters learned in Platt scaling to\n",
      " |      produce probability estimates from decision values. If\n",
      " |      probability=False, an empty array. Platt scaling uses the logistic\n",
      " |      function\n",
      " |      ``1 / (1 + exp(decision_value * probA_ + probB_))``\n",
      " |      where ``probA_`` and ``probB_`` are learned from the dataset [2]_. For\n",
      " |      more information on the multiclass case and training procedure see\n",
      " |      section 8 of [1]_.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> import numpy as np\n",
      " |  >>> X = np.array([[-1, -1], [-2, -1], [1, 1], [2, 1]])\n",
      " |  >>> y = np.array([1, 1, 2, 2])\n",
      " |  >>> from sklearn.svm import SVC\n",
      " |  >>> clf = SVC(gamma='auto')\n",
      " |  >>> clf.fit(X, y) #doctest: +NORMALIZE_WHITESPACE\n",
      " |  SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      " |      decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      " |      max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      " |      tol=0.001, verbose=False)\n",
      " |  >>> print(clf.predict([[-0.8, -1]]))\n",
      " |  [1]\n",
      " |  \n",
      " |  See also\n",
      " |  --------\n",
      " |  SVR\n",
      " |      Support Vector Machine for Regression implemented using libsvm.\n",
      " |  \n",
      " |  LinearSVC\n",
      " |      Scalable Linear Support Vector Machine for classification\n",
      " |      implemented using liblinear. Check the See also section of\n",
      " |      LinearSVC for more comparison element.\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  .. [1] `LIBSVM: A Library for Support Vector Machines\n",
      " |      <http://www.csie.ntu.edu.tw/~cjlin/papers/libsvm.pdf>`_\n",
      " |  \n",
      " |  .. [2] `Platt, John (1999). \"Probabilistic outputs for support vector\n",
      " |      machines and comparison to regularizedlikelihood methods.\"\n",
      " |      <http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.41.1639>`_\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      SVC\n",
      " |      sklearn.svm.base.BaseSVC\n",
      " |      sklearn.svm.base.BaseLibSVM\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, C=1.0, kernel='rbf', degree=3, gamma='auto_deprecated', coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, decision_function_shape='ovr', random_state=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.svm.base.BaseSVC:\n",
      " |  \n",
      " |  decision_function(self, X)\n",
      " |      Evaluates the decision function for the samples in X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape (n_samples, n_features)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X : array-like, shape (n_samples, n_classes * (n_classes-1) / 2)\n",
      " |          Returns the decision function of the sample for each class\n",
      " |          in the model.\n",
      " |          If decision_function_shape='ovr', the shape is (n_samples,\n",
      " |          n_classes).\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If decision_function_shape='ovo', the function values are proportional\n",
      " |      to the distance of the samples X to the separating hyperplane. If the\n",
      " |      exact distances are required, divide the function values by the norm of\n",
      " |      the weight vector (``coef_``). See also `this question\n",
      " |      <https://stats.stackexchange.com/questions/14876/\n",
      " |      interpreting-distance-from-hyperplane-in-svm>`_ for further details.\n",
      " |      If decision_function_shape='ovr', the decision function is a monotonic\n",
      " |      transformation of ovo decision function.\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Perform classification on samples in X.\n",
      " |      \n",
      " |      For an one-class model, +1 or -1 is returned.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      " |          For kernel=\"precomputed\", the expected shape of X is\n",
      " |          [n_samples_test, n_samples_train]\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y_pred : array, shape (n_samples,)\n",
      " |          Class labels for samples in X.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.svm.base.BaseSVC:\n",
      " |  \n",
      " |  predict_log_proba\n",
      " |      Compute log probabilities of possible outcomes for samples in X.\n",
      " |      \n",
      " |      The model need to have probability information computed at training\n",
      " |      time: fit with attribute `probability` set to True.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape (n_samples, n_features)\n",
      " |          For kernel=\"precomputed\", the expected shape of X is\n",
      " |          [n_samples_test, n_samples_train]\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      T : array-like, shape (n_samples, n_classes)\n",
      " |          Returns the log-probabilities of the sample for each class in\n",
      " |          the model. The columns correspond to the classes in sorted\n",
      " |          order, as they appear in the attribute `classes_`.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The probability model is created using cross validation, so\n",
      " |      the results can be slightly different than those obtained by\n",
      " |      predict. Also, it will produce meaningless results on very small\n",
      " |      datasets.\n",
      " |  \n",
      " |  predict_proba\n",
      " |      Compute probabilities of possible outcomes for samples in X.\n",
      " |      \n",
      " |      The model need to have probability information computed at training\n",
      " |      time: fit with attribute `probability` set to True.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape (n_samples, n_features)\n",
      " |          For kernel=\"precomputed\", the expected shape of X is\n",
      " |          [n_samples_test, n_samples_train]\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      T : array-like, shape (n_samples, n_classes)\n",
      " |          Returns the probability of the sample for each class in\n",
      " |          the model. The columns correspond to the classes in sorted\n",
      " |          order, as they appear in the attribute `classes_`.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The probability model is created using cross validation, so\n",
      " |      the results can be slightly different than those obtained by\n",
      " |      predict. Also, it will produce meaningless results on very small\n",
      " |      datasets.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.svm.base.BaseLibSVM:\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None)\n",
      " |      Fit the SVM model according to the given training data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      " |          Training vectors, where n_samples is the number of samples\n",
      " |          and n_features is the number of features.\n",
      " |          For kernel=\"precomputed\", the expected shape of X is\n",
      " |          (n_samples, n_samples).\n",
      " |      \n",
      " |      y : array-like, shape (n_samples,)\n",
      " |          Target values (class labels in classification, real numbers in\n",
      " |          regression)\n",
      " |      \n",
      " |      sample_weight : array-like, shape (n_samples,)\n",
      " |          Per-sample weights. Rescale C per sample. Higher weights\n",
      " |          force the classifier to put more emphasis on these points.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If X and y are not C-ordered and contiguous arrays of np.float64 and\n",
      " |      X is not a scipy.sparse.csr_matrix, X and/or y may be copied.\n",
      " |      \n",
      " |      If X is a dense array, then the other methods will not support sparse\n",
      " |      matrices as input.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.svm.base.BaseLibSVM:\n",
      " |  \n",
      " |  coef_\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Returns the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like, shape = (n_samples) or (n_samples, n_outputs)\n",
      " |          True labels for X.\n",
      " |      \n",
      " |      sample_weight : array-like, shape = [n_samples], optional\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of self.predict(X) wrt. y.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='rbf', max_iter=-1, probability=False, random_state=0,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "help(SVC)\n",
    "classifier = SVC(kernel = 'rbf', random_state = 0)\n",
    "classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = classifier.predict(x_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[65,  3],\n",
       "       [ 3, 29]], dtype=int64)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9004226918798665"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "#help(cross_val_score)\n",
    "accuracies = cross_val_score(estimator = classifier, X = x_train, y = y_train, cv = 10)\n",
    "accuracies.mean()\n",
    "#accuracies.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bala\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(C=1, base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0.1, kernel='rbf',\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
       "              nthread=None, objective='binary:logistic', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "#help(GridSearchCV)\n",
    "parameters = [{'C':[1,10,100,1000], 'kernel' : ['linear']},\n",
    "             {'C':[1,10,100,1000], 'kernel' : ['rbf'], 'gamma' : [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]}]\n",
    "grid_search = GridSearchCV(estimator = classifier,\n",
    "                          param_grid = parameters,\n",
    "                          scoring = 'accuracy',\n",
    "                          cv = 10,\n",
    "                          n_jobs = -1)\n",
    "grid_search = grid_search.fit(x_train, y_train)\n",
    "grid_search.best_score_\n",
    "grid_search.best_params_\n",
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "def plot_color_graph(x_set, y_set):\n",
    "    x1, x2 = np.meshgrid(np.arange(start = x_set[:, 0].min() - 1, stop = x_set[:, 0].max() + 1, step = 0.01),\n",
    "                        np.arange(start = x_set[:, 0].min() - 1, stop = x_set[:, 0].max() + 1, step = 0.01))\n",
    "    plt.contourf(x1, x2, classifier.predict(np.array([x1.ravel(), x2.ravel()]).T).reshape(x1.shape),\n",
    "                alpha = 0.75, cmap = ListedColormap(('red','green')))\n",
    "    plt.xlim(x1.min(), x1.max())\n",
    "    plt.ylim(x2.min(), x2.max())\n",
    "    for i, j in enumerate(np.unique(y_set)):\n",
    "        plt.scatter(x_set[y_set == j, 0], x_set[y_set == j, 1],\n",
    "                   c = ListedColormap(('red','green'))(i), label = j)\n",
    "    plt.title('Mesh Graph')\n",
    "    plt.xlabel('Age')\n",
    "    plt.ylabel('Salary')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n",
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_color_graph(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n",
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_color_graph(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8333333333333334"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.5 * 10 /(0.6 * 1000))*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10/30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class XGBClassifier in module xgboost.sklearn:\n",
      "\n",
      "class XGBClassifier(XGBModel, sklearn.base.ClassifierMixin)\n",
      " |  XGBClassifier(max_depth=3, learning_rate=0.1, n_estimators=100, verbosity=1, silent=None, objective='binary:logistic', booster='gbtree', n_jobs=1, nthread=None, gamma=0, min_child_weight=1, max_delta_step=0, subsample=1, colsample_bytree=1, colsample_bylevel=1, colsample_bynode=1, reg_alpha=0, reg_lambda=1, scale_pos_weight=1, base_score=0.5, random_state=0, seed=None, missing=None, **kwargs)\n",
      " |  \n",
      " |  Implementation of the scikit-learn API for XGBoost classification.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  max_depth : int\n",
      " |      Maximum tree depth for base learners.\n",
      " |  learning_rate : float\n",
      " |      Boosting learning rate (xgb's \"eta\")\n",
      " |  n_estimators : int\n",
      " |      Number of trees to fit.\n",
      " |  verbosity : int\n",
      " |      The degree of verbosity. Valid values are 0 (silent) - 3 (debug).\n",
      " |  silent : boolean\n",
      " |      Whether to print messages while running boosting. Deprecated. Use verbosity instead.\n",
      " |  objective : string or callable\n",
      " |      Specify the learning task and the corresponding learning objective or\n",
      " |      a custom objective function to be used (see note below).\n",
      " |  booster: string\n",
      " |      Specify which booster to use: gbtree, gblinear or dart.\n",
      " |  nthread : int\n",
      " |      Number of parallel threads used to run xgboost.  (Deprecated, please use ``n_jobs``)\n",
      " |  n_jobs : int\n",
      " |      Number of parallel threads used to run xgboost.  (replaces ``nthread``)\n",
      " |  gamma : float\n",
      " |      Minimum loss reduction required to make a further partition on a leaf node of the tree.\n",
      " |  min_child_weight : int\n",
      " |      Minimum sum of instance weight(hessian) needed in a child.\n",
      " |  max_delta_step : int\n",
      " |      Maximum delta step we allow each tree's weight estimation to be.\n",
      " |  subsample : float\n",
      " |      Subsample ratio of the training instance.\n",
      " |  colsample_bytree : float\n",
      " |      Subsample ratio of columns when constructing each tree.\n",
      " |  colsample_bylevel : float\n",
      " |      Subsample ratio of columns for each level.\n",
      " |  colsample_bynode : float\n",
      " |      Subsample ratio of columns for each split.\n",
      " |  reg_alpha : float (xgb's alpha)\n",
      " |      L1 regularization term on weights\n",
      " |  reg_lambda : float (xgb's lambda)\n",
      " |      L2 regularization term on weights\n",
      " |  scale_pos_weight : float\n",
      " |      Balancing of positive and negative weights.\n",
      " |  base_score:\n",
      " |      The initial prediction score of all instances, global bias.\n",
      " |  seed : int\n",
      " |      Random number seed.  (Deprecated, please use random_state)\n",
      " |  random_state : int\n",
      " |      Random number seed.  (replaces seed)\n",
      " |  missing : float, optional\n",
      " |      Value in the data which needs to be present as a missing value. If\n",
      " |      None, defaults to np.nan.\n",
      " |  importance_type: string, default \"gain\"\n",
      " |      The feature importance type for the feature_importances_ property: either \"gain\",\n",
      " |      \"weight\", \"cover\", \"total_gain\" or \"total_cover\".\n",
      " |  \\*\\*kwargs : dict, optional\n",
      " |      Keyword arguments for XGBoost Booster object.  Full documentation of parameters can\n",
      " |      be found here: https://github.com/dmlc/xgboost/blob/master/doc/parameter.rst.\n",
      " |      Attempting to set a parameter via the constructor args and \\*\\*kwargs dict simultaneously\n",
      " |      will result in a TypeError.\n",
      " |  \n",
      " |      .. note:: \\*\\*kwargs unsupported by scikit-learn\n",
      " |  \n",
      " |          \\*\\*kwargs is unsupported by scikit-learn.  We do not guarantee that parameters\n",
      " |          passed via this argument will interact properly with scikit-learn.\n",
      " |  \n",
      " |  Note\n",
      " |  ----\n",
      " |  A custom objective function can be provided for the ``objective``\n",
      " |  parameter. In this case, it should have the signature\n",
      " |  ``objective(y_true, y_pred) -> grad, hess``:\n",
      " |  \n",
      " |  y_true: array_like of shape [n_samples]\n",
      " |      The target values\n",
      " |  y_pred: array_like of shape [n_samples]\n",
      " |      The predicted values\n",
      " |  \n",
      " |  grad: array_like of shape [n_samples]\n",
      " |      The value of the gradient for each sample point.\n",
      " |  hess: array_like of shape [n_samples]\n",
      " |      The value of the second derivative for each sample point\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      XGBClassifier\n",
      " |      XGBModel\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, max_depth=3, learning_rate=0.1, n_estimators=100, verbosity=1, silent=None, objective='binary:logistic', booster='gbtree', n_jobs=1, nthread=None, gamma=0, min_child_weight=1, max_delta_step=0, subsample=1, colsample_bytree=1, colsample_bylevel=1, colsample_bynode=1, reg_alpha=0, reg_lambda=1, scale_pos_weight=1, base_score=0.5, random_state=0, seed=None, missing=None, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  evals_result(self)\n",
      " |      Return the evaluation results.\n",
      " |      \n",
      " |      If **eval_set** is passed to the `fit` function, you can call\n",
      " |      ``evals_result()`` to get evaluation results for all passed **eval_sets**.\n",
      " |      When **eval_metric** is also passed to the `fit` function, the\n",
      " |      **evals_result** will contain the **eval_metrics** passed to the `fit` function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      evals_result : dictionary\n",
      " |      \n",
      " |      Example\n",
      " |      -------\n",
      " |      \n",
      " |      .. code-block:: python\n",
      " |      \n",
      " |          param_dist = {'objective':'binary:logistic', 'n_estimators':2}\n",
      " |      \n",
      " |          clf = xgb.XGBClassifier(**param_dist)\n",
      " |      \n",
      " |          clf.fit(X_train, y_train,\n",
      " |                  eval_set=[(X_train, y_train), (X_test, y_test)],\n",
      " |                  eval_metric='logloss',\n",
      " |                  verbose=True)\n",
      " |      \n",
      " |          evals_result = clf.evals_result()\n",
      " |      \n",
      " |      The variable **evals_result** will contain\n",
      " |      \n",
      " |      .. code-block:: python\n",
      " |      \n",
      " |          {'validation_0': {'logloss': ['0.604835', '0.531479']},\n",
      " |          'validation_1': {'logloss': ['0.41965', '0.17686']}}\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None, eval_set=None, eval_metric=None, early_stopping_rounds=None, verbose=True, xgb_model=None, sample_weight_eval_set=None, callbacks=None)\n",
      " |      Fit gradient boosting classifier\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array_like\n",
      " |          Feature matrix\n",
      " |      y : array_like\n",
      " |          Labels\n",
      " |      sample_weight : array_like\n",
      " |          Weight for each instance\n",
      " |      eval_set : list, optional\n",
      " |          A list of (X, y) pairs to use as a validation set for\n",
      " |          early-stopping\n",
      " |      sample_weight_eval_set : list, optional\n",
      " |          A list of the form [L_1, L_2, ..., L_n], where each L_i is a list of\n",
      " |          instance weights on the i-th validation set.\n",
      " |      eval_metric : str, callable, optional\n",
      " |          If a str, should be a built-in evaluation metric to use. See\n",
      " |          doc/parameter.rst. If callable, a custom evaluation metric. The call\n",
      " |          signature is func(y_predicted, y_true) where y_true will be a\n",
      " |          DMatrix object such that you may need to call the get_label\n",
      " |          method. It must return a str, value pair where the str is a name\n",
      " |          for the evaluation and value is the value of the evaluation\n",
      " |          function. This objective is always minimized.\n",
      " |      early_stopping_rounds : int, optional\n",
      " |          Activates early stopping. Validation error needs to decrease at\n",
      " |          least every <early_stopping_rounds> round(s) to continue training.\n",
      " |          Requires at least one item in evals. If there's more than one,\n",
      " |          will use the last. If early stopping occurs, the model will have\n",
      " |          three additional fields: bst.best_score, bst.best_iteration and\n",
      " |          bst.best_ntree_limit (bst.best_ntree_limit is the ntree_limit parameter\n",
      " |          default value in predict method if not any other value is specified).\n",
      " |          (Use bst.best_ntree_limit to get the correct value if num_parallel_tree\n",
      " |          and/or num_class appears in the parameters)\n",
      " |      verbose : bool\n",
      " |          If `verbose` and an evaluation set is used, writes the evaluation\n",
      " |          metric measured on the validation set to stderr.\n",
      " |      xgb_model : str\n",
      " |          file name of stored xgb model or 'Booster' instance Xgb model to be\n",
      " |          loaded before training (allows training continuation).\n",
      " |      callbacks : list of callback functions\n",
      " |          List of callback functions that are applied at end of each iteration.\n",
      " |          It is possible to use predefined callbacks by using :ref:`callback_api`.\n",
      " |          Example:\n",
      " |      \n",
      " |          .. code-block:: python\n",
      " |      \n",
      " |              [xgb.callback.reset_learning_rate(custom_rates)]\n",
      " |  \n",
      " |  predict(self, data, output_margin=False, ntree_limit=None, validate_features=True)\n",
      " |      Predict with `data`.\n",
      " |      \n",
      " |      .. note:: This function is not thread safe.\n",
      " |      \n",
      " |        For each booster object, predict can only be called from one thread.\n",
      " |        If you want to run prediction using multiple thread, call ``xgb.copy()`` to make copies\n",
      " |        of model object and then call ``predict()``.\n",
      " |      \n",
      " |      .. note:: Using ``predict()`` with DART booster\n",
      " |      \n",
      " |        If the booster object is DART type, ``predict()`` will perform dropouts, i.e. only\n",
      " |        some of the trees will be evaluated. This will produce incorrect results if ``data`` is\n",
      " |        not the training data. To obtain correct results on test sets, set ``ntree_limit`` to\n",
      " |        a nonzero value, e.g.\n",
      " |      \n",
      " |        .. code-block:: python\n",
      " |      \n",
      " |          preds = bst.predict(dtest, ntree_limit=num_round)\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : DMatrix\n",
      " |          The dmatrix storing the input.\n",
      " |      output_margin : bool\n",
      " |          Whether to output the raw untransformed margin value.\n",
      " |      ntree_limit : int\n",
      " |          Limit number of trees in the prediction; defaults to best_ntree_limit if defined\n",
      " |          (i.e. it has been trained with early stopping), otherwise 0 (use all trees).\n",
      " |      validate_features : bool\n",
      " |          When this is True, validate that the Booster's and data's feature_names are identical.\n",
      " |          Otherwise, it is assumed that the feature_names are the same.\n",
      " |      Returns\n",
      " |      -------\n",
      " |      prediction : numpy array\n",
      " |  \n",
      " |  predict_proba(self, data, ntree_limit=None, validate_features=True)\n",
      " |      Predict the probability of each `data` example being of a given class.\n",
      " |      \n",
      " |      .. note:: This function is not thread safe\n",
      " |      \n",
      " |          For each booster object, predict can only be called from one thread.\n",
      " |          If you want to run prediction using multiple thread, call ``xgb.copy()`` to make copies\n",
      " |          of model object and then call predict\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : DMatrix\n",
      " |          The dmatrix storing the input.\n",
      " |      ntree_limit : int\n",
      " |          Limit number of trees in the prediction; defaults to best_ntree_limit if defined\n",
      " |          (i.e. it has been trained with early stopping), otherwise 0 (use all trees).\n",
      " |      validate_features : bool\n",
      " |          When this is True, validate that the Booster's and data's feature_names are identical.\n",
      " |          Otherwise, it is assumed that the feature_names are the same.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      prediction : numpy array\n",
      " |          a numpy array with the probability of each data example being of a given class.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from XGBModel:\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  apply(self, X, ntree_limit=0)\n",
      " |      Return the predicted leaf every tree for each sample.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array_like, shape=[n_samples, n_features]\n",
      " |          Input features matrix.\n",
      " |      \n",
      " |      ntree_limit : int\n",
      " |          Limit number of trees in the prediction; defaults to 0 (use all trees).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_leaves : array_like, shape=[n_samples, n_trees]\n",
      " |          For each datapoint x in X and for each tree, return the index of the\n",
      " |          leaf x ends up in. Leaves are numbered within\n",
      " |          ``[0; 2**(self.max_depth+1))``, possibly with gaps in the numbering.\n",
      " |  \n",
      " |  get_booster(self)\n",
      " |      Get the underlying xgboost Booster of this model.\n",
      " |      \n",
      " |      This will raise an exception when fit was not called\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      booster : a xgboost booster of underlying model\n",
      " |  \n",
      " |  get_num_boosting_rounds(self)\n",
      " |      Gets the number of xgboost boosting rounds.\n",
      " |  \n",
      " |  get_params(self, deep=False)\n",
      " |      Get parameters.\n",
      " |  \n",
      " |  get_xgb_params(self)\n",
      " |      Get xgboost type parameters.\n",
      " |  \n",
      " |  load_model(self, fname)\n",
      " |      Load the model from a file.\n",
      " |      \n",
      " |      The model is loaded from an XGBoost internal binary format which is\n",
      " |      universal among the various XGBoost interfaces. Auxiliary attributes of\n",
      " |      the Python Booster object (such as feature names) will not be loaded.\n",
      " |      Label encodings (text labels to numeric labels) will be also lost.\n",
      " |      **If you are using only the Python interface, we recommend pickling the\n",
      " |      model object for best results.**\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      fname : string or a memory buffer\n",
      " |          Input file name or memory buffer(see also save_raw)\n",
      " |  \n",
      " |  save_model(self, fname)\n",
      " |      Save the model to a file.\n",
      " |      \n",
      " |      The model is saved in an XGBoost internal binary format which is\n",
      " |      universal among the various XGBoost interfaces. Auxiliary attributes of\n",
      " |      the Python Booster object (such as feature names) will not be loaded.\n",
      " |      Label encodings (text labels to numeric labels) will be also lost.\n",
      " |      **If you are using only the Python interface, we recommend pickling the\n",
      " |      model object for best results.**\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      fname : string\n",
      " |          Output file name\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      Modification of the sklearn method to allow unknown kwargs. This allows using\n",
      " |      the full range of xgboost parameters that are not defined as member variables\n",
      " |      in sklearn grid search.\n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from XGBModel:\n",
      " |  \n",
      " |  coef_\n",
      " |      Coefficients property\n",
      " |      \n",
      " |      .. note:: Coefficients are defined only for linear learners\n",
      " |      \n",
      " |          Coefficients are only defined when the linear model is chosen as base\n",
      " |          learner (`booster=gblinear`). It is not defined for other base learner types, such\n",
      " |          as tree learners (`booster=gbtree`).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      coef_ : array of shape ``[n_features]`` or ``[n_classes, n_features]``\n",
      " |  \n",
      " |  feature_importances_\n",
      " |      Feature importances property\n",
      " |      \n",
      " |      .. note:: Feature importance is defined only for tree boosters\n",
      " |      \n",
      " |          Feature importance is only defined when the decision tree model is chosen as base\n",
      " |          learner (`booster=gbtree`). It is not defined for other base learner types, such\n",
      " |          as linear learners (`booster=gblinear`).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      feature_importances_ : array of shape ``[n_features]``\n",
      " |  \n",
      " |  intercept_\n",
      " |      Intercept (bias) property\n",
      " |      \n",
      " |      .. note:: Intercept is defined only for linear learners\n",
      " |      \n",
      " |          Intercept (bias) is only defined when the linear model is chosen as base\n",
      " |          learner (`booster=gblinear`). It is not defined for other base learner types, such\n",
      " |          as tree learners (`booster=gbtree`).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      intercept_ : array of shape ``(1,)`` or ``[n_classes]``\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Returns the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like, shape = (n_samples) or (n_samples, n_outputs)\n",
      " |          True labels for X.\n",
      " |      \n",
      " |      sample_weight : array-like, shape = [n_samples], optional\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of self.predict(X) wrt. y.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
       "              nthread=None, objective='binary:logistic', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "help(XGBClassifier)\n",
    "classifier = XGBClassifier()\n",
    "classifier.fit(x_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
